---
title: "日本人英語学習者の文理解における色表象の活性化-言語間比較と習熟度の観点から-"
subtitle: "D2報告会 February 3rd, 2022"
author: "*Masato Terai*"
date: "最終更新: `r Sys.time()`"
output:
  html_document:
    toc: yes
    toc_depth: 4
    toc_float: yes
    number_sections: yes
#    df_print: "paged"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE, tidy=TRUE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = 'center'
)
# knitr::opts_knit$set(root.dir = '/tmp')
```

```{r message=FALSE, warning=FALSE, tidy=TRUE, include=FALSE}
library(tidyverse)
library(lme4)
library(report)
library(lmerTest)
library(sjPlot)
library(plotly)
library(qqplotr)
library(ggpubr)
library(ggmosaic)
library(kableExtra)
```

# 質問です

## どのような場面でしょう？

"*The train came out of the long tunnel into the snow country.*"

## 川端康成（雪国）

「国境の長いトンネルを抜けると雪国であった。」（川端康成『雪国』）

"*The train came out of the long tunnel into the snow country.*"
(訳　サイデンステッカー)

-   心に真っ白な銀世界が思い浮かびましたか？
-   母語と外国語で思い浮かべたものに違いはありましたか？

# 研究の目的

-   外国語においても、母語のように言語表現が示す物体を活性化しながら理解を行うのかを明らかにする

    -   日本のように外国語として英語を学習する環境
    -   外国語：教室内での記号的な操作による学習（*Dog* = 犬）

# 先行研究

## 身体化認知研究（基盤化された認知）

### **知覚的シンボルシステム（Perceptual Symbol System:PSS）**

-   シミュレーション：周囲の環境や身体、心との関わりで経験し、獲得された知覚運動表象表象の再現（[Barsalou, 2008](https://bit.ly/3IN8Gn1)）

-   言語理解においても、発話や書き言葉が表す意味を表象するためにシミュレーションを行う（[Barsalou, 1999](https://bit.ly/3g1wG9M)）

![「イス」の理解プロセス](https://drive.google.com/uc?export=view&id=1wIWTbF2X2MVGODcnUuCJRBqcwbqbG6Ed "「イス」の理解プロセス"){width="80%"}

## **知覚的シンボルシステムの妥当性**


-   母語の研究
  -   以下の物体の視覚特性をシミュレーションする

    -   形 e.g., [Zwaan et al. (2002)](https://bit.ly/3qztk4u)

    -   方向 e.g., [Zwaan and Pecher (2012)](https://bit.ly/3oo0nFO)

    -   色 e.g., [Connell & Lynott (2009)](https://bit.ly/3CEGxeU)

    -   などなど

## Connell and Lynott (2009)

### 色の表象

-   文理解におけるシミュレーションを、色の表象に着目

-   意味ストループ課題

    -   文章を読んだ直後に提示される単語の色を読み上げる
    -   文章内で暗示された単語の色 = 提示された単語の色 -\>
        読み上げ速度が速くなる

<center>

![](https://drive.google.com/uc?export=view&id=1q2_yHOISAWrPkT7o6uobrj8tcTkhKGsN){width="60%"}

</center>

## **イメージの内容**

-   シミュレーションでは複数の色が表象されるか？

    -   茶色のクマ（典型）
    -   白色のクマ（ホッキョクグマ） (非典型)
    -   黄色のクマ（現実にはあり得ない）

<center>

![](https://drive.google.com/uc?export=view&id=13uK4EHsjihw1Rb-NxEIAOjZwPOkcxuhm){width="60%"}

</center>

### 外国語の研究

-   シミュレーションの有無の研究

    -   L2でも知覚運動表象が活性化

        -    e.g., Buccino et al. (2017) : 触りやすさ（触覚）

-   習熟度の影響・イメージの精緻さ（日本人英語学習者）

    -   粟津・鈴木（2020）**低熟達度**の学習者でも身体性の影響を報告

        -   行為文における時相の影響（精緻さ） =\> 条件間の有意さ無し
        
    -   L2では活性化しない

        -    Norman and Peleg (2021): 視覚

## 先行研究の課題

### 母語の研究

-   色という視覚情報を活性化するか？

    -   Connell and Lynott (2009)の追試

        -   文の種類と文字の種類の色の交互作用があるか

        -   日本語でも再現できるか

-   複数のイメージの活性化を行うか？

    -   非典型な文を理解する際に、文脈を定義する表現がキーワードの前に来た場合でも典型的なイメージのシミュレーションを行うのか
    
-   文脈を先に定義すると一つのイメージしかできない？

-   **現在**

    <center>

    ![](https://drive.google.com/uc?export=view&id=1MgHdo1NBCMehO9f2rSt1VSman4TAAqez){width="60%"}

    </center>

    <br>

-   **変更後**

    <center>

    ![](https://drive.google.com/uc?export=view&id=1VU9iYDOnHJ4eEijpBtORx9HHATWsk1lw){width="60%"}

    </center>


### 外国語の研究

-   外国語でも母語のような処理を行うか?

    -   習熟度の向上とともにシミュレーションの程度や内容は母語に近づくか

## 研究課題

1.  外国語においてもイメージの活性化は行われているのか
2.  外国語の文理解の際に想起するイメージは、指示対象一つにつき一つか
3.  外国語の習熟度の高低によって，想起するイメージの質・内容は変化するか

# 本研究

## **仮説**

-   日本人が**日本語**で課題を行う場合、Connell and Lynott
    (2009)が再現できる

    -   文が示す色と単語の色が同じ =\> 最速

    -   非典型的な色を示す文の後に典型的な色と非典型な色 =\>
        速度は変わらない

-   日本人が**英語**で課題を行う場合

    -   習熟度によって、条件間の速度の差は異なる

        -   英語の習熟度が高いと、母語での反応に近づくため、条件間の速度の差が大きくなる

# 本実験

## 実験素材

-   二回の予備実験で項目を作成

-   360の文（英語版と日本語版がある）

    -   実験文：180文（文脈前: 90文、文脈前: 90文）

        -   90文

            -   2（文章の種類） × 3（単語の色の種類）= 6条件

            -   15（キーワード） × 6条件 = 90文

    -   フィラー文：180文（文脈前: 90文、文脈前: 90文）

        -   全ての実験文はこちらの[OSFのページ](https://osf.io/hjrma/?view_only=cfcd339a544e4f7d93c845571014da7d)に掲載

+----------------------+-----------------------+-----------------------+
|                      | 文脈の位置            | 文脈の位置            |
+======================+:=====================:+:=====================:+
| **文章の種類**       | 前                    | 後ろ                  |
+----------------------+-----------------------+-----------------------+
| 典型                 | **In the woods,** Joe | Joe was excited to    |
|                      | was excited to see *a | see *a bear* **in the |
|                      | bear*.                | woods**.              |
+----------------------+-----------------------+-----------------------+
| 非典型               | **At the North        | Joe was excited to    |
|                      | Pole,** Joe was       | see *a bear* **at the |
|                      | excited to see *a     | North Pole**.         |
|                      | bear*.                |                       |
+----------------------+-----------------------+-----------------------+

: 刺激文の例

## **手順**

-   [意味ストループ課題](https://youtu.be/oROfQVYQs6c)

    -   Set 1 (文脈**前**の実験文　+ 文脈**後**のフィラー) or
        (文脈**後ろ**の実験文　+ 文脈**前**のフィラー)

    -   [冠詞穴埋め課題](https://youtu.be/5_eoGb-ZicI)（一定の時間を空けるため）

    -   Set 2 (文脈**後**の実験文　+ 文脈**前**のフィラー) or
        (文脈**前**の実験文　+ 文脈**後**のフィラー)

-   単語のイメージ判断課題

    -   予備実験とは異なる形式（6段階で各単語と色の組み合わせの評価）

-   文章のイメージ判断課題

-   アンケート

## 参加者の数の決定

### 検定力分析

-   Connell and Lynott (2009)で報告されている効果量は以下の通り

    -   文字の色の主効果（**有意**）：一般化イータ二乗（.050）

        -   水元 & 竹内（2008）の表1によると、やや中程度

    -   文章の文字の色（**有意でない**）：一般化イータ二乗（\< .0001）

        -   水元 & 竹内（2008）の表1によると、かなり小さい

    -   文章の色と文字の色の交互作用（**有意でない**）：一般化イータ二乗（.008）

        -   水元 & 竹内（2008）の表1によると、小さい

-   よって、今回はCohen (1988)の効果量 *d* をもとに検定力を算出した。

    -   一般化イータ二乗の数値を見ると、かなり小さい効果量からやや中程度の効果量までの幅がある。
    -   そこで今回は、効果量を少なく設定した（*d* = 0.2）。
    -   さらに、一人当たりの実験項目数は180項目であった (実験文の90 +
        フィラーの90)

```{r, warning=FALSE, echo=FALSE}
    #install.packages("sjstats", dependencies = T)
    library(sjstats)
    power.sjstats <- sjstats::samplesize_mixed(
    eff.size = 0.2, #effect size
    df.n = NULL, #degree of freedom
    power = 0.8,
    sig.level = 0.05,
    k = NULL, #LEVEL2が参加者で、ここを推定したいからNULLに
    n = 180, #Optionalだが、k = NULLならここは必須, number of observations per cluster groups
    icc = 0.05 #Expected intraclass correlation coefficient for multilevel-model.
    )

    power.sjstats
    power.sjstats$`Total Sample Size`
```

-   分析の結果、43.5名となった。したがって、44名を対象に実験を行えば、検定力80%を満たす。

```{r}
power.sjstats$`Total Sample Size`/ 180 #Required observations / the number of items
```

# 本実験の経過報告

# **評価課題の分析**

## **単語単位**

```{r, tidy=TRUE, include=FALSE}
files <- list.files(path = "C:/Users/mtera/Documents/Terai_color/Main_Color/color_Nativespeaker_main_experiment/data/Stroop_Color_Native/", pattern = "EN_main")

setwd("C:/Users/mtera/Documents/Terai_color/Main_Color/color_Nativespeaker_main_experiment/data/Stroop_Color_Native/")

bind_data <- NULL
for (i in 1:length(files)) {
  all_data <- read.table(files[i],sep = "\t", fill = TRUE, quote = "", skip = 1)
  bind_data <- rbind(bind_data, all_data)
}

bind_data <- bind_data[,-1]

colnames(bind_data) <- c("SubjectID", "ItemID","Set","Position","Trials", "Sentence","Type","Sentence.Typicality",
                           "Word","Word.Typicality", "Correct.Answer","Combination","Comprehension.question","Comprehension.answer", "Stroop.responce", "RT.Stroop","Responce.Color","RT.Sentence","Comprehension.responce","RT.comprehension")
```

```{r, tidy=TRUE, include=FALSE}
setwd("C:/Users/mtera/Desktop/")
dat_word_rating <- read.csv("Rating.csv", header = T, encoding = "UTF-8")[,-c(1,2)]
```

```{r, tidy=TRUE, include=FALSE}
  word_rating <- NULL
  header <- names(dat_word_rating[,-1])
    for (i in 1:(length(header))) {
        dat_word_rating %>%
        dplyr::select(ID, i + 1) -> eachdata
        eachdata[,3] <- header[i]
        word_rating <- rbind(word_rating, sapply(eachdata, as.character))
    }
   all_word_data <- as_tibble(word_rating)
   colnames(all_word_data) <- c("ID", "rating", "Item")
   
   all_word_data <- all_word_data %>%
     tidyr::separate(Item, into = c("a", "color", "word"), sep = "\\.") %>%
     dplyr::select(-a)
   
    referencelist.word <- bind_data %>%
        dplyr::filter(SubjectID == 1) %>%
        dplyr::filter(Position == "Post") %>%
        dplyr::filter(Combination == "typical-typical" | Combination == "typical-atypical"| Combination == "typical-unrelated") %>%
        dplyr::select(Word, Word.Typicality, Correct.Answer)
    
    referencelist.word$Word %>%
        stringr::str_to_lower()
    
    colnames(referencelist.word) <- c("word","typicality.of.the.word","The color of the Word")
    
    all_word_data <- all_word_data %>%
        mutate(typ.word = paste(!!!rlang::syms(c("color","word")), sep="-"))
    
   referencelist.word <- referencelist.word %>%
        mutate(typ.word = paste(!!!rlang::syms(c("The color of the Word","word")), sep="-"))
    
    all_word_data.new <- all_word_data %>%
       dplyr::left_join(referencelist.word, by = "typ.word") 
    
    all_word_data.new <- all_word_data.new [,-c(6,8)]
    colnames(all_word_data.new) <- c("SubjectID", "Rating.Score", "Color", "Word", "Color-Word", "Typicality")
```

## 評価値（全体）

-   それぞれの単語において、Typicalの評価値はAtypicalよりも高いことが望ましい。<br>また、Unrelatedの評価値はAtypicalよりも低いことが望ましい。さらに、Unrelatedの評価値は1から2が望ましい。
-   以下の図では、評価値の平均が2未満の行に色を塗った。

```{r, tidy=TRUE, echo=FALSE}
all_word_data.new$Rating.Score <- as.numeric(all_word_data.new$Rating.Score)
all_word_data.new <- all_word_data.new %>%
  mutate(Typicality = fct_relevel(Typicality, "typical","atypical", "unrelated"))
    

  all_word_data.new %>%
    group_by(Word, `Color-Word`,Typicality) %>%
    summarize(mean = round(mean(Rating.Score), 2), 
              sd = round(sd(Rating.Score),2),
              .groups = "drop") %>%
    arrange(Word,Typicality) %>%
    mutate(mean = as.numeric(mean)) %>%
    mutate(sd = as.numeric(sd)) -> Ratings.new
  
  Ratings.new %>%
    kableExtra::kbl( 
               digits = 2, 
               align = "c", 
                booktabs = T,
               caption = "The rating scores of each words") %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = T) %>%
    # cell_spec(color = case_when(
    #   Ratings.new$mean >= 4 ~ "blue",
    #   Ratings.new$mean >=2 & Ratings.new$mean < 4 ~"red",
    #   Ratings.new$mean >=1 & Ratings.new$mean < 2 ~ "yellow")) 
    row_spec(which(Ratings.new$mean < 2 ), background  = "lightblue")
  #参考：https://community.rstudio.com/t/conditional-formatting-with-column-spec-within-a-dplyr-chain/84347/4
    
```

## **文単位**

```{r, tidy=TRUE, include=FALSE}
setwd("C:/Users/mtera/Desktop/")
dat_A_main <- read.csv("sentenceA_main.csv", header = T, encoding = "UTF-8")[,-c(1,2)]
dat_B_main <- read.csv("sentenceB_main.csv", header = T, encoding = "UTF-8")[,-c(1,2)]
```

```{r, tidy=TRUE, include=FALSE}
  sentence_A <- NULL
  header <- names(dat_A_main[,-1])
    for (i in 1:(length(header))) {
        dat_A_main %>%
        dplyr::select(ID, i + 1) -> eachdata
        eachdata[,3] <- header[i]
        sentence_A <- rbind(sentence_A, sapply(eachdata, as.character))
        }

  sentence_B <- NULL
  header <- names(dat_B_main[,-1])
    for (i in 1:(length(header))) {
        dat_B_main %>%
        dplyr::select(ID, i + 1) -> eachdata
        eachdata[,3] <- header[i]
        sentence_B <- rbind(sentence_B, sapply(eachdata, as.character))
        }

  all_sentence_data <- as_tibble((rbind(sentence_A, sentence_B)))

  colnames(all_sentence_data) <- c("ID", "ratings", "sentence")
    
  all_sentence_data$ratings <- as.factor(all_sentence_data$ratings)
  pacman::p_load(forcats)
  fct_list <- c("typical" = "best matched by Picture 1",
                "atypical" = "best matched by Picture 2",
                "both" = "matched by both pictures equally",
                "neither" = "matched by neither picture")
  
  #Picture 1 is always typical object.
  #Picture 2 is always atypical object.
  all_sentence_data <- all_sentence_data %>% 
  dplyr::mutate(ratings = fct_recode(ratings, !!!fct_list))
  
  all_sentence_data$sentence <- gsub("\\.", " ", all_sentence_data$sentence)
 
  #Encoding等の関係でハイフンなどが消えたりしたものを修正
  pacman::p_load(forcats)
  fct_list <- c(
    "Ben popped a piece of popcorn in his mouth and it tasted sour " = "Ben popped a piece of popcorn in his mouth  and it tasted sour ",
    "Ben popped a piece of popcorn in his mouth and it tasted sweet " = "Ben popped a piece of popcorn in his mouth  and it tasted sweet ",
    "The strawberry that Mark bought looked ready to eat " = "The strawberry that Mark bought looked ready to eat ",
    "The strawberry that Mark bought didn't look ready to eat " = "The strawberry that Mark bought didn t look ready to eat ",
    "The teacher pointed to the chameleon lying camouflaged in the grass " = "The teacher pointed to the chameleon lying camouflaged in the grass ",
    "The teacher pointed to the chameleon lying camouflaged in the sand  " = "The teacher pointed to the chameleon lying camouflaged in the sand ",
    "John looked at the steak on his plate " = "John looked at the steak on his plate ",
    "John looked at the steak in the meat-shop " = "John looked at the steak in the meat shop ",
    "Lynn ordered a cake for Valentine's Day " = "Lynn ordered a cake for Valentine s Day ")
  all_sentence_data <- all_sentence_data %>% 
  dplyr::mutate(sentence = fct_recode(sentence, !!!fct_list))
  
  referencelist <- bind_data %>%
    dplyr::filter(SubjectID == 1) %>%
    dplyr::filter(Position == "Post") %>%
    dplyr::filter(Combination == "typical-typical" | Combination == "atypical-atypical") %>%
    dplyr::select(ItemID, Word,Sentence, Sentence.Typicality)
   referencelist$referencelist <- gsub("\\.", " ", referencelist$Sentence)
   referencelist <- tibble(referencelist)[,-3]
   colnames(referencelist) <- c("ItemID","word","typicality.of.the.sentence","sentence")
  
  all_sentence_data.new <- all_sentence_data %>%
     dplyr::left_join(referencelist, by = "sentence") 
  
  all_sentence_data.new <- all_sentence_data.new %>%
    mutate(typ.sen = paste(!!!rlang::syms(c("typicality.of.the.sentence","word")), sep="-")) %>%
    mutate(order = paste(!!!rlang::syms(c("word", "typicality.of.the.sentence")), sep="-"))
 
  #factor方のままだと、因子の数が合わないと怒られるのでcharacterに変更してからmatchさせる 
  all_sentence_data.new$ratings <- as.character(all_sentence_data.new$ratings)
  all_sentence_data.new$typicality.of.the.sentence <- as.character(all_sentence_data.new$typicality.of.the.sentence)
  
  all_sentence_data.new <- all_sentence_data.new  %>%
    mutate(match = if_else(typicality.of.the.sentence == ratings, "1", "0")) 
  
  all_sentence_data.new <- all_sentence_data.new  %>%
    mutate(typicality.of.the.sentence = fct_relevel(typicality.of.the.sentence, "typical","atypical")) %>%
    mutate(ratings = fct_relevel(ratings, "typical","atypical", "both", "neither")) 
```

```{r, tidy=TRUE, echo=FALSE}
  balloon.plot <- all_sentence_data.new %>%
    group_by(typ.sen,ratings,order) %>%
    summarize(n = n(),
              .groups = "drop") %>%
    arrange(n)
```

```{r, tidy=TRUE, echo=FALSE, fig.dim = c(12, 6)}
  balloon.plot %>%
    ggplot(aes(x = order, y = ratings)) +
    geom_point(aes(size = n), shape = 21, colour = "black",
               fill = "skyblue") +
    scale_size_area(max_size =10, guide = "none") +
    geom_text(aes(label=n)) +
         theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1)) +
         theme(axis.text.y = element_text(size = 10)) +
         theme(axis.title.y = element_text(size = 10)) +
         theme(axis.title.x = element_text(size = 10))
```

```{r, echo=FALSE}
  all_sentence_data.new$match <- as.numeric(all_sentence_data.new$match)

  Matchtypicality <- all_sentence_data.new %>%
    group_by(order) %>%
    summarise(mean = round(mean(match), 3)*100, 
              sd = round(sd(match),3),
              .groups = "drop") %>%
    arrange(mean)

  kableExtra::kbl(Matchtypicality[1:5,], 
               digits = 2, 
               align = "c", 
                booktabs = T,
               caption = "The typicalities of each sentences ( % )") %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = T) %>%
   row_spec(which(Matchtypicality$mean < 25 ), background  = "lightblue")
```

## 意味ストループ課題

### **全体の傾向**

```{r, tidy=TRUE, include=FALSE}
files <- list.files(path = "C:/Users/mtera/Documents/Terai_color/Main_Color/color_Nativespeaker_main_experiment/data/Stroop_Color_Native/", pattern = "EN_main")

setwd("C:/Users/mtera/Documents/Terai_color/Main_Color/color_Nativespeaker_main_experiment/data/Stroop_Color_Native/")

bind_data <- NULL
for (i in 1:length(files)) {
  all_data <- read.table(files[i],sep = "\t", fill = TRUE, quote = "", skip = 1)
  bind_data <- rbind(bind_data, all_data)
}

bind_data <- bind_data[,-1]

colnames(bind_data) <- c("SubjectID", "ItemID","Set","Position","Trials", "Sentence","Type","Sentence.Typicality",
                           "Word","Word.Typicality", "Correct.Answer","Combination","Comprehension.question","Comprehension.answer", "Stroop.responce", "RT.Stroop","Responce.Color","RT.Sentence","Comprehension.responce","RT.comprehension")
```

```{r, tidy=TRUE, include=FALSE}
#Next, load in the data and convert data frame to tibble.  
bind_data <- as_tibble(bind_data) ### Convert to tibble
bind_data$SubjectID <- as.factor(bind_data$SubjectID)
bind_data$ItemID <- factor(bind_data$ItemID)
bind_data$Set <- as.factor(bind_data$Set)
bind_data$Position <- as.factor(bind_data$Position)
bind_data$Pres.Order <- as.numeric(bind_data$Trials)
bind_data$Type <- as.factor(bind_data$Type)
bind_data$Sentence.Typicality <- factor(bind_data$Sentence.Typicality)
bind_data$Word.Typicality <- factor(bind_data$Word.Typicality)
bind_data$Combination <- as.factor(bind_data$Combination)
bind_data$Stroop.res <- factor(bind_data$Stroop.responce)
bind_data$RT.Stroop <- as.numeric(bind_data$RT.Stroop)
bind_data$Comp.res <- as.numeric(bind_data$Comprehension.responce)
head(bind_data) ### Overview of the data
```

```{r, tidy=TRUE,echo=FALSE}
knitr::kable(table(bind_data$Stroop.res),
             col.names = c("Correct / Incorrect", "Raw Frequency"),
             digits = 2,
             align = "c",
             caption = "English") %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = T)
```

```{r, tidy=TRUE, include=FALSE}
bind_data %>% 
  filter (!is.na(Comprehension.responce)) %>%
  group_by(SubjectID) %>%
  summarize(Comp.res = mean(Comprehension.responce)) %>% arrange(Comp.res) 
```

```{r, tidy=TRUE, include=FALSE}
bind_data %>%
    filter(Type == "target") %>%
    group_by(Word) %>%
    summarise(mean = mean(RT.Stroop), 
              sd = sd(RT.Stroop),
              .groups = "drop") %>%
    arrange(mean)
```

## **英語**

```{r, tidy=TRUE, include=FALSE}
bind_data %>% 
  filter(Type == "target") -> EN.target
```

## 参加者のデータの概要（個別）

```{r, echo=FALSE, tidy=TRUE, warning=FALSE, fig.dim = c(10, 6)}

EN.target %>%
  ggplot(aes(x= Trials, y= RT.Stroop, colour = Set)) +
  geom_point() +
  stat_smooth(method = 'loess', level = 0.95) +
  ylim(0,3500) +
  facet_wrap(~SubjectID)

```

## **データ・クリーニング**

-   以下の条件に該当するデータは、以下の分析には含まれていない <br> <br>

    -   不正解の正答 <br> <br>

    -   フィラー項目 <br> <br>

    -   内容理解課題の全体の正答率が**50%未満**の参加者の**すべて**のデータ
        <br> <br>

    -   ストループ課題の全体の正答率が**80%未満**の参加者の**すべて**のデータ
        <br> <br>

    -   正答率・反応速度が、*± 3 median absolute
        deviations*離れている項目 <br> <br> <br>

-   以上の条件は [Horchak and Garrido
    (2020)](https://bit.ly/3zALIdQ)を参考にした

```{r, warning=FALSE, tidy=TRUE,include=FALSE}
bind_data %>%
  filter(!is.na(Comprehension.responce)) %>%
  filter(!is.na(Stroop.responce)) %>%
  group_by(SubjectID) %>%
  summarize(Comp.res = mean(Comprehension.responce), Stroop.res = mean(Stroop.responce), .groups = "drop") %>%
  filter(Comp.res < 0.5 | Stroop.res < 0.8) -> excluded


excluded$SubjectID

bind_data %>%
  filter(Type != "filler") %>%
  filter(RT.Stroop != 0) %>%
  filter(Stroop.res == 1) %>%
  #filter(SubjectID != "5") %>%
  filter(RT.Stroop < 3*mad(RT.Stroop)) %>%
  filter(RT.Stroop > -3*mad(RT.Stroop)) -> EN.model

```

```{r, echo=FALSE, tidy=TRUE, warning=FALSE, fig.dim = c(10, 6)}

EN.model %>%
  ggplot(aes(x= Trials, y= RT.Stroop, colour = Set)) +
  geom_point() +
  stat_smooth(method = 'loess', level = 0.95) +
  ylim(0,3500) +
  facet_wrap(~SubjectID)

```

# 反応速度：ストループ課題

## 研究課題1（先行研究の結果は再現できるか）

### 反応速度（英語：実験項目：文脈後）

-   クリーニング後のデータ
-   予測

1.  典型的な文 - 典型的な単語の色
2.  非典型的な文 - 典型的な単語の色 = 非典型的な文 - 非典型的な単語の色
3.  典型的な文 - 非典型的な単語の色 = 典型的な文 - ありえない単語の色 =
    非典型的な文 - ありえない単語の色

-   エラーバーは測定誤差

```{r, tidy=TRUE,echo=FALSE}
Post.RT.percon <- EN.model %>% 
  filter(Position == "Post") %>%
  group_by(Combination) %>%
  summarise(n_acc = n(),mean_acc=round(mean(RT.Stroop),2),sd_acc=sd(RT.Stroop),.groups = "drop") %>%
   mutate(se.acc = sd_acc/sqrt(n_acc),
         lower.ci.acc = round (mean_acc - qt(1 - (0.05 / 2), n_acc - 1) * se.acc,2),
         upper.ci.acc = round (mean_acc + qt(1 - (0.05 / 2), n_acc - 1) * se.acc,2)) %>%
  arrange(mean_acc)

kableExtra::kbl(Post.RT.percon,
             col.names = c("condition","N", "mean","SD",
                           "SE", "CI:lower", "CI:upper"),
             digits = 2, 
             booktabs = T,
             align = "c",
             caption = "Target: Reaction Time of the semantic stroop task: Post") %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = T) %>%
   row_spec(which(Post.RT.percon$Combination == "typical-unrelated") , background  = "lightblue") %>%
   row_spec(which(Post.RT.percon$Combination == "atypical-unrelated") , background  = "lightblue")
```

```{r, echo=FALSE, warning=FALSE, fig.dim = c(10, 4)}
EN.model %>%
  mutate(Word.Typicality = fct_relevel(Word.Typicality,
                              levels = c("typical", "atypical", "unrelated"))) %>%
   mutate(Sentence.Typicality = fct_relevel(Sentence.Typicality,
                              levels = c("typical", "atypical", "unrelated"))) %>%
  filter(Position == "Post") %>%
  group_by(Sentence.Typicality, Word.Typicality) %>%
  summarise(mean = mean(RT.Stroop),
            sd = sd(RT.Stroop),
            n = n(),
            se = sd/sqrt(n),.groups = "drop") %>%
  ggplot(aes(x = Sentence.Typicality, y = mean, fill = Word.Typicality)) +
    geom_col(position = "dodge") +
    geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                  position =position_dodge(0.9), width = .2) +
  scale_y_continuous(breaks = seq(0,700,10)) +
  coord_cartesian(ylim = c(500,700))  +
  scale_fill_viridis_d()-> zz

ggplotly(zz)
```

## 研究課題2（文脈の位置による違い）

### 反応速度（英語：実験項目：文脈前）

-   クリーニング後

1.  典型的な文 - 典型的な単語の色
2.  非典型的な文 - 非典型的な単語の色 \*1と2の条件には有意差なし
3.  非典型的な文 - 典型的な単語の色 \*2と3の条件に有意差あり
4.  典型的な文 - 非典型的な単語の色 = 典型的な文 - ありえない単語の色 =
    非典型的な文 - ありえない単語の色

```{r, tidy=TRUE,echo=FALSE}
Pre.RT.percon <- EN.model %>% 
  filter(Position == "Pre") %>%
  group_by(Combination) %>%
  summarise(n_acc = n(),mean_acc=round(mean(RT.Stroop),2),sd_acc=sd(RT.Stroop),.groups = "drop") %>%
   mutate(se.acc = sd_acc/sqrt(n_acc),
         lower.ci.acc = round (mean_acc - qt(1 - (0.05 / 2), n_acc - 1) * se.acc,2),
         upper.ci.acc = round (mean_acc + qt(1 - (0.05 / 2), n_acc - 1) * se.acc,2)) %>%
  arrange(mean_acc)

kableExtra::kbl(Pre.RT.percon,
             col.names = c("condition","N", "mean","SD",
                           "SE", "CI:lower", "CI:upper"),
             digits = 2, 
             booktabs = T,
             align = "c",
             caption = "Target: Reaction Time of the semantic stroop task: Post") %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = T)  %>%
   row_spec(which(Pre.RT.percon$Combination == "typical-unrelated") , background  = "lightblue") %>%
   row_spec(which(Pre.RT.percon$Combination == "atypical-unrelated") , background  = "lightblue")
```

```{r, echo=FALSE, warning=FALSE, fig.dim = c(10, 4)}
EN.model %>%
  mutate(Word.Typicality = fct_relevel(Word.Typicality,
                              levels = c("typical", "atypical", "unrelated"))) %>%
   mutate(Sentence.Typicality = fct_relevel(Sentence.Typicality,
                              levels = c("typical", "atypical", "unrelated"))) %>%
  filter(Position == "Pre") %>%
  group_by(Sentence.Typicality, Word.Typicality) %>%
  summarise(mean = mean(RT.Stroop),
            sd = sd(RT.Stroop),
            n = n(),
            se = sd/sqrt(n),.groups = "drop") %>%
  ggplot(aes(x = Sentence.Typicality, y = mean, fill = Word.Typicality)) +
    geom_col(position = "dodge") +
    geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                  position =position_dodge(0.9), width = .2) +
  scale_y_continuous(breaks = seq(0,700,10)) +
  coord_cartesian(ylim = c(500,700)) +
  scale_fill_viridis_d()-> zzz

ggplotly(zzz)
```

# **今後の計画**

-   データ収集の80%を**4月**までに完了

1.  英語母語話者を対象に実験

    -   残り**25**名

2.  日本人を対象に日本語で実験

    -   残り**44**名

3.  日本人を対象に英語で実験

    -   残り**44**名

-   "It didn't look**ed**"のような文法ミスを修正して日本人への実験に
-   **5月**までにデータ分析の完了
-   ランダム構造の設計
-   確率分布の指定

# 引用文献
